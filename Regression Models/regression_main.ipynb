{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main file for regression models (exlcuding LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from regression_helper_functions_03 import ts_data, train_test, train_validation, plot_acutal_predict, model_performance, rmse, convert, performance_table, naive_baseline, grid_search_ses, grid_search_gbr, gbr, grid_search_rf, grid_search_sarima, sarima, arima_predict, grid_search_arima, performance_table_single\n",
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_naive_baseline(CONT, FREQ, PREDICT_HORIZON):\n",
    "    MODEL_RESULTS = dict()\n",
    "    for i in CONT:\n",
    "        MODEL_RESULTS[i] = {'MODEL':[],'RUN_TIME':[], 'Frequency':[], 'Prediction_Window':[], 'RMSE':[], 'NRMSE':[], 'MAPE':[], 'ND':[]}\n",
    "    \n",
    "    for c in CONT:\n",
    "            for f in FREQ:\n",
    "                for p in PREDICT_HORIZON:\n",
    "                    x = ts_data(country = c, category = 'total', frequency = f, model = None)\n",
    "\n",
    "                    #augmented out of sample training \n",
    "                    train_s = int(len(x)*0.7)\n",
    "                    test_s = len(x) - train_s\n",
    "                    t = list()\n",
    "                    t_ = list()\n",
    "                    idx = list()\n",
    "\n",
    "                    START_TIME = timeit.default_timer()\n",
    "\n",
    "                    for i in range(0,int(test_s/p)):\n",
    "                        train, test = train_test(x,train_s,p)\n",
    "\n",
    "                        y_hat = naive_baseline(train, test)\n",
    "                        idx = idx + list(test.index)\n",
    "                        t_ = t_ + list(y_hat.values)\n",
    "                        t = t + list(test.values)\n",
    "                        train_s += p\n",
    "\n",
    "                    END_TIME = timeit.default_timer()\n",
    "                    TIME = convert(END_TIME-START_TIME)\n",
    "\n",
    "                    y_real = pd.DataFrame(t,index=idx)\n",
    "                    y_pred = pd.DataFrame(t_,index=idx)\n",
    "                    mape, rmse, nrmse, nd = model_performance(y_real, y_pred)\n",
    "\n",
    "                    MODEL_RESULTS[c]['MODEL'].append('NAIVE_BASELINE')\n",
    "                    MODEL_RESULTS[c]['RUN_TIME'].append(TIME)\n",
    "                    MODEL_RESULTS[c]['Frequency'].append(f)\n",
    "                    MODEL_RESULTS[c]['Prediction_Window'].append(p)\n",
    "                    MODEL_RESULTS[c]['RMSE'].append(rmse)\n",
    "                    MODEL_RESULTS[c]['MAPE'].append(mape)\n",
    "                    MODEL_RESULTS[c]['NRMSE'].append(nrmse)\n",
    "                    MODEL_RESULTS[c]['ND'].append(nd)\n",
    "            \n",
    "    return performance_table(MODEL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple Exponential Smoothing\n",
    "def run_ses(CONT, FREQ, PREDICT_HORIZON):\n",
    "    \n",
    "    MODEL_RESULTS = dict()\n",
    "    for i in CONT:\n",
    "        MODEL_RESULTS[i] = {'MODEL':[],'RUN_TIME':[], 'Frequency':[], 'Prediction_Window':[], 'RMSE':[], 'NRMSE':[], 'MAPE':[], 'ND':[]}\n",
    "    \n",
    "    for c in CONT:\n",
    "        for f in FREQ:\n",
    "            for p in PREDICT_HORIZON:\n",
    "                x = ts_data(country = c, category = 'total', frequency = f, model = None)\n",
    "                #grid search using 70% of the original data\n",
    "                train_data_gs, test_data_gs = train_test(x,int(len(x)*0.7),0)\n",
    "                alpha = grid_search_ses(train_data_gs)\n",
    "\n",
    "                #augmented out of sample training \n",
    "                train_s = int(len(x)*0.7)\n",
    "                test_s = len(x) - train_s\n",
    "                t = list()\n",
    "                t_ = list()\n",
    "                idx = list()\n",
    "                \n",
    "                START_TIME = timeit.default_timer()\n",
    "                \n",
    "                for i in range(0,int(test_s/p)):\n",
    "                    train, test = train_test(x,train_s,p)\n",
    "\n",
    "                    y_hat = SimpleExpSmoothing(train).fit(smoothing_level=alpha,optimized=False).forecast(p)\n",
    "\n",
    "                    idx = idx + list(test.index)\n",
    "                    t_ = t_ + list(y_hat.values)\n",
    "                    t = t + list(test.values)\n",
    "                    train_s += p\n",
    "                    \n",
    "                END_TIME = timeit.default_timer()\n",
    "                TIME = convert(END_TIME-START_TIME)\n",
    "                \n",
    "                y_real = pd.DataFrame(t,index=idx)\n",
    "                y_pred = pd.DataFrame(t_,index=idx)\n",
    "                mape, rmse, nrmse, nd = model_performance(y_real, y_pred)\n",
    "                \n",
    "                MODEL_RESULTS[c]['MODEL'].append('SES')\n",
    "                MODEL_RESULTS[c]['RUN_TIME'].append(TIME)\n",
    "                MODEL_RESULTS[c]['Frequency'].append(f)\n",
    "                MODEL_RESULTS[c]['Prediction_Window'].append(p)\n",
    "                MODEL_RESULTS[c]['RMSE'].append(rmse)\n",
    "                MODEL_RESULTS[c]['MAPE'].append(mape)\n",
    "                MODEL_RESULTS[c]['NRMSE'].append(nrmse)\n",
    "                MODEL_RESULTS[c]['ND'].append(nd)\n",
    "            \n",
    "    return performance_table(MODEL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#GBR\n",
    "def run_gbr(CONT, FREQ, PREDICT_HORIZON):\n",
    "    \n",
    "    MODEL_RESULTS = dict()\n",
    "    for i in CONT:\n",
    "        MODEL_RESULTS[i] = {'MODEL':[],'RUN_TIME':[], 'Frequency':[], 'Prediction_Window':[], 'RMSE':[], 'NRMSE':[], 'MAPE':[], 'ND':[]}\n",
    "    \n",
    "    for c in CONT:\n",
    "        for f in FREQ:\n",
    "            for p in PREDICT_HORIZON:\n",
    "                x, dt = ts_data(country = c, category = 'total', frequency = f, model = 'gbr_rf')\n",
    "                #grid search using 70% of the original data\n",
    "                train_data_gs, test_data_gs = train_test(x,int(len(x)*0.7),0)\n",
    "                gbr_parameters = grid_search_gbr(train_data_gs)\n",
    "\n",
    "                #augmented out of sample training \n",
    "                train_s = int(len(x)*0.7)\n",
    "                test_s = len(x) - train_s\n",
    "                t = list()\n",
    "                t_ = list()\n",
    "                idx = list()\n",
    "                \n",
    "                START_TIME = timeit.default_timer()\n",
    "                \n",
    "                for i in range(0,int(test_s/p)):\n",
    "                    train, test = train_test(x,train_s,p)\n",
    "\n",
    "                    train_input = train.drop(['y'], axis=1)\n",
    "                    test_input = test.drop(['y'], axis=1)\n",
    "\n",
    "                    y_hat = gbr(train_input,train['y'],test_input,gbr_parameters)\n",
    "\n",
    "                    idx = idx + list(test.index)\n",
    "                    t_ = t_ + list(y_hat)\n",
    "                    t = t + list(test['y'].values)\n",
    "                    train_s += p\n",
    "                    \n",
    "                END_TIME = timeit.default_timer()\n",
    "                TIME = convert(END_TIME-START_TIME)\n",
    "                \n",
    "                y_real = pd.DataFrame(t,index=idx)\n",
    "                y_pred = pd.DataFrame(t_,index=idx)\n",
    "                mape, rmse, nrmse, nd = model_performance(y_real, y_pred)\n",
    "\n",
    "                MODEL_RESULTS[c]['MODEL'].append('GBR')\n",
    "                MODEL_RESULTS[c]['RUN_TIME'].append(TIME)\n",
    "                MODEL_RESULTS[c]['Frequency'].append(f)\n",
    "                MODEL_RESULTS[c]['Prediction_Window'].append(p)\n",
    "                MODEL_RESULTS[c]['RMSE'].append(rmse)\n",
    "                MODEL_RESULTS[c]['MAPE'].append(mape)\n",
    "                MODEL_RESULTS[c]['NRMSE'].append(nrmse)\n",
    "                MODEL_RESULTS[c]['ND'].append(nd)\n",
    "                \n",
    "    return performance_table(MODEL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF\n",
    "def run_rf(CONT, FREQ, PREDICT_HORIZON):\n",
    "    MODEL_RESULTS = dict()\n",
    "    for i in CONT:\n",
    "        MODEL_RESULTS[i] = {'MODEL':[],'RUN_TIME':[], 'Frequency':[], 'Prediction_Window':[], 'RMSE':[], 'NRMSE':[], 'MAPE':[], 'ND':[]}\n",
    "    for c in CONT:\n",
    "        for f in FREQ:\n",
    "            for p in PREDICT_HORIZON:\n",
    "                x, dt = ts_data(country = c, category = 'total', frequency = f, model = 'gbr_rf')\n",
    "                #grid search using 70% of the original data\n",
    "                train_data_gs, test_data_gs = train_test(x,int(len(x)*0.7),0)\n",
    "                rf_parameters = grid_search_rf(train_data_gs)\n",
    "\n",
    "                #augmented out of sample training \n",
    "                train_s = int(len(x)*0.7)\n",
    "                test_s = len(x) - train_s\n",
    "                t = list()\n",
    "                t_ = list()\n",
    "                idx = list()\n",
    "\n",
    "                START_TIME = timeit.default_timer()\n",
    "\n",
    "                for i in range(0,int(test_s/p)):\n",
    "                    train, test = train_test(x,train_s,p)\n",
    "\n",
    "                    train_input = train.drop(['y'], axis=1)\n",
    "                    test_input = test.drop(['y'], axis=1)\n",
    "\n",
    "                    model = RandomForestRegressor(n_estimators = rf_parameters[0], max_features = rf_parameters[1], \n",
    "                                                  max_depth = rf_parameters[2], random_state = 42).fit(train_input, train['y'])\n",
    "                    y_hat = model.predict(test_input)\n",
    "\n",
    "                    idx = idx + list(test.index)\n",
    "                    t_ = t_ + list(y_hat)\n",
    "                    t = t + list(test['y'].values)\n",
    "                    train_s += p\n",
    "\n",
    "                END_TIME = timeit.default_timer()\n",
    "                TIME = convert(END_TIME-START_TIME)\n",
    "\n",
    "                y_real = pd.DataFrame(t,index=idx)\n",
    "                y_pred = pd.DataFrame(t_,index=idx)\n",
    "                mape, rmse, nrmse, nd = model_performance(y_real, y_pred)\n",
    "\n",
    "                MODEL_RESULTS[c]['MODEL'].append('RF')\n",
    "                MODEL_RESULTS[c]['RUN_TIME'].append(TIME)\n",
    "                MODEL_RESULTS[c]['Frequency'].append(f)\n",
    "                MODEL_RESULTS[c]['Prediction_Window'].append(p)\n",
    "                MODEL_RESULTS[c]['RMSE'].append(rmse)\n",
    "                MODEL_RESULTS[c]['MAPE'].append(mape)\n",
    "                MODEL_RESULTS[c]['NRMSE'].append(nrmse)\n",
    "                MODEL_RESULTS[c]['ND'].append(nd)\n",
    "\n",
    "    return performance_table(MODEL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ARIMA\n",
    "def run_arima(CONT, FREQ, PREDICT_HORIZON):\n",
    "    \n",
    "    MODEL_RESULTS = dict()\n",
    "    for i in CONT:\n",
    "        MODEL_RESULTS[i] = {'MODEL':[],'RUN_TIME':[], 'Frequency':[], 'Prediction_Window':[], 'RMSE':[], 'NRMSE':[], 'MAPE':[], 'ND':[]}\n",
    "    \n",
    "    for c in CONT:\n",
    "        for f in FREQ:\n",
    "            for p in PREDICT_HORIZON:\n",
    "                x = ts_data(country = c, category = 'total', frequency = f, model = None)\n",
    "                #grid search using 70% of the original data\n",
    "                train_data_gs, test_data_gs = train_test(x,int(len(x)*0.7),0)\n",
    "                arima_parameters = grid_search_arima(train_data_gs)\n",
    "\n",
    "                #augmented out of sample training \n",
    "                train_s = int(len(x)*0.7)\n",
    "                test_s = len(x) - train_s\n",
    "                t = list()\n",
    "                t_ = list()\n",
    "                idx = list()\n",
    "                \n",
    "                START_TIME = timeit.default_timer()\n",
    "                \n",
    "                for i in range(0,int(test_s/p)):\n",
    "                    train, test = train_test(x,train_s,p)\n",
    "                    y_hat = ARIMA(train, arima_parameters).fit(disp=False).predict(start=len(train),end=len(train)+p-1)\n",
    "\n",
    "                    idx = idx + list(test.index)\n",
    "                    t_ = t_ + list(y_hat.values)\n",
    "                    t = t + list(test.values)\n",
    "                    train_s += p\n",
    "                    \n",
    "                END_TIME = timeit.default_timer()\n",
    "                TIME = convert(END_TIME-START_TIME)\n",
    "                \n",
    "                y_real = pd.DataFrame(t,index=idx)\n",
    "                y_pred = pd.DataFrame(t_,index=idx)\n",
    "                mape, rmse, nrmse, nd = model_performance(y_real, y_pred)              \n",
    "                \n",
    "                MODEL_RESULTS[c]['MODEL'].append('ARIMA')\n",
    "                MODEL_RESULTS[c]['RUN_TIME'].append(TIME)\n",
    "                MODEL_RESULTS[c]['Frequency'].append(f)\n",
    "                MODEL_RESULTS[c]['Prediction_Window'].append(p)\n",
    "                MODEL_RESULTS[c]['RMSE'].append(rmse)\n",
    "                MODEL_RESULTS[c]['MAPE'].append(mape)\n",
    "                MODEL_RESULTS[c]['NRMSE'].append(nrmse)\n",
    "                MODEL_RESULTS[c]['ND'].append(nd)\n",
    "\n",
    "    return performance_table(MODEL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sarima(CONT, FREQ, PREDICT_HORIZON):\n",
    "    MODEL_RESULTS = dict()\n",
    "    for i in CONT:\n",
    "        MODEL_RESULTS[i] = {'MODEL':[],'RUN_TIME':[], 'Frequency':[], 'Prediction_Window':[], 'RMSE':[], 'NRMSE':[], 'MAPE':[], 'ND':[]}\n",
    "    \n",
    "    for c in CONT:\n",
    "        for f in FREQ:\n",
    "            for p in PREDICT_HORIZON:\n",
    "                x = ts_data(country = c, category = 'total', frequency = f, model = None)\n",
    "                #grid search using 70% of the original data\n",
    "                train_data_gs, test_data_gs = train_test(x,int(len(x)*0.7),0)\n",
    "                pqd = grid_search_sarima(train_data_gs)\n",
    "\n",
    "                #augmented out of sample training \n",
    "                train_s = int(len(x)*0.7)\n",
    "                test_s = len(x) - train_s\n",
    "                t = list()\n",
    "                t_ = list()\n",
    "                idx = list()\n",
    "                \n",
    "                START_TIME = timeit.default_timer()\n",
    "                \n",
    "                for i in range(0,int(test_s/p)):\n",
    "\n",
    "                    train, test = train_test(x,train_s,p)\n",
    "                    y_hat = sarima(pqd[0][0],pqd[0][1],pqd[0][2],pqd[1][0],pqd[1][1],pqd[1][2],train\n",
    "                                  ).get_forecast(steps=p).conf_int()\n",
    "                    y_hat['y'] = (y_hat['lower y'] + y_hat['upper y'])/2\n",
    "        \n",
    "                    idx = idx + list(test.index)\n",
    "                    t_ = t_ + list(y_hat['y'].values)\n",
    "                    t = t + list(test.values)\n",
    "\n",
    "                    train_s += p\n",
    "                    \n",
    "                    \n",
    "                END_TIME = timeit.default_timer()\n",
    "                TIME = convert(END_TIME-START_TIME)\n",
    "                \n",
    "                y_real = pd.DataFrame(t,index=idx)\n",
    "                y_pred = pd.DataFrame(t_,index=idx)\n",
    "                mape, rmse, nrmse, nd = model_performance(y_real, y_pred)\n",
    "                \n",
    "                print('c, f, p', c, f, p, 'parameters', pqd)\n",
    "                \n",
    "                MODEL_RESULTS[c]['MODEL'].append('SARIMA')\n",
    "                MODEL_RESULTS[c]['RUN_TIME'].append(TIME)\n",
    "                MODEL_RESULTS[c]['Frequency'].append(f)\n",
    "                MODEL_RESULTS[c]['Prediction_Window'].append(p)\n",
    "                MODEL_RESULTS[c]['RMSE'].append(rmse)\n",
    "                MODEL_RESULTS[c]['MAPE'].append(mape)\n",
    "                MODEL_RESULTS[c]['NRMSE'].append(nrmse)\n",
    "                MODEL_RESULTS[c]['ND'].append(nd)\n",
    "                print(MODEL_RESULTS)\n",
    "    return performance_table_single(MODEL_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FREQ = ['2H']\n",
    "PREDICT_HORIZON = [6,12,24]\n",
    "CONT = ['CA']\n",
    "\n",
    "TABLE_SARIMA = run_sarima(CONT, FREQ, PREDICT_HORIZON)\n",
    "\n",
    "TABLE_SARIMA.to_csv('Regression_Performance_SARIMA_CA_P2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "FREQ = ['1H','2H']\n",
    "PREDICT_HORIZON = [1, 6, 12, 24, 72]\n",
    "CONT = ['US','CA','GB','ENTIRE','NORTH_AMERICA']\n",
    "\n",
    "TABLE_NAIVE_BASELINE = run_naive_baseline(CONT, FREQ, PREDICT_HORIZON)\n",
    "TABLE_SES = run_ses(CONT, FREQ, PREDICT_HORIZON)\n",
    "TABLE_GBR = run_gbr(CONT, FREQ, PREDICT_HORIZON)\n",
    "TABLE_RF = run_rf(CONT, FREQ, PREDICT_HORIZON)\n",
    "TABLE_ARIMA = run_arima(CONT, FREQ, PREDICT_HORIZON)\n",
    "\n",
    "#save output to csv\n",
    "TABLES = [TABLE_SES, TABLE_GBR, TABLE_NAIVE_BASELINE, TABLE_RF, TABLE_ARIMA]\n",
    "REGRESSION_PERFORMANCE = pd.concat(TABLES)\n",
    "\n",
    "REGRESSION_PERFORMANCE.to_csv('Regression_Performance.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "FREQ = ['24H']\n",
    "PREDICT_HORIZON = [1, 6, 12, 24]\n",
    "CONT = ['US','CA','GB','ENTIRE','NORTH_AMERICA']\n",
    "\n",
    "TABLE_SES = run_ses(CONT, FREQ, PREDICT_HORIZON)\n",
    "TABLE_GBR = run_gbr(CONT, FREQ, PREDICT_HORIZON)\n",
    "TABLE_RF = run_rf(CONT, FREQ, PREDICT_HORIZON)\n",
    "TABLE_ARIMA = run_arima(CONT, FREQ, PREDICT_HORIZON)\n",
    "\n",
    "#save output to csv\n",
    "TABLES = [TABLE_SES, TABLE_GBR, TABLE_RF, TABLE_ARIMA]\n",
    "REGRESSION_PERFORMANCE = pd.concat(TABLES)\n",
    "\n",
    "REGRESSION_PERFORMANCE.to_csv('Regression_Performance_24H.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
