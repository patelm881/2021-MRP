{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main file for classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from classification_helper_functions_ import DTW, ts_data, performance_table, convert, model_performance, train_test, train_test_split_classification, lstm, train_test_lstm, split_series, performance_table_lstm, plot_acutal_predict, naive_baseline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import timeit\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.spatial import distance\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function for RF classification\n",
    "def run_rf(CONT, FREQ, PREDICT_HORIZON):\n",
    "    MODEL_RESULTS = dict()\n",
    "    for i in CONT:\n",
    "        MODEL_RESULTS[i] = {'MODEL':[],'RUN_TIME':[], 'Frequency':[], 'Prediction_Window':[], 'ACCURACY':[], \n",
    "                         'F1SCORE':[], 'PRECISION':[], 'RECALL':[]}\n",
    "    for c in CONT:\n",
    "        for f in FREQ:\n",
    "            for p in PREDICT_HORIZON:\n",
    "                X, dt, lb = ts_data(country = c, category = 'total', frequency = f, model = None) # build the dataset\n",
    "                train_s = int(len(X)*0.7)\n",
    "                test_s = len(X) - train_s\n",
    "                t = list()\n",
    "                t_ = list()\n",
    "                idx = list()\n",
    "\n",
    "                START_TIME = timeit.default_timer()\n",
    "\n",
    "                for i in range(0,int(test_s/p)):\n",
    "                    x_train, x_test, y_train, y_test = train_test_split_classification(X, train_s, p)\n",
    "                    \n",
    "                    # train the classifier \n",
    "                    clf=RandomForestClassifier(n_estimators=100)\n",
    "                    clf.fit(x_train,y_train)\n",
    "                    \n",
    "                    for j in range(0,p): # make classifications p-steps out of sample\n",
    "                        x_test_temp = [x_test.iloc[j]]\n",
    "                        y_pred=clf.predict(x_test_temp)\n",
    "\n",
    "                        t_ = t_ + list(y_pred)\n",
    "                        t = t + [list(y_test)[j]]\n",
    "                    \n",
    "                    train_s += p\n",
    "\n",
    "                END_TIME = timeit.default_timer()\n",
    "                TIME = convert(END_TIME-START_TIME)\n",
    "                \n",
    "                # calculate model performance and return results in a dataframe \n",
    "                accuracy, f1score, precision, recall = model_performance(t_, t)\n",
    "                \n",
    "                MODEL_RESULTS[c]['MODEL'].append('RF')\n",
    "                MODEL_RESULTS[c]['RUN_TIME'].append(TIME)\n",
    "                MODEL_RESULTS[c]['Frequency'].append(f)\n",
    "                MODEL_RESULTS[c]['Prediction_Window'].append(p)\n",
    "                MODEL_RESULTS[c]['ACCURACY'].append(accuracy)\n",
    "                MODEL_RESULTS[c]['F1SCORE'].append(f1score)\n",
    "                MODEL_RESULTS[c]['PRECISION'].append(precision)\n",
    "                MODEL_RESULTS[c]['RECALL'].append(recall)\n",
    "    return performance_table(MODEL_RESULTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function for XGB\n",
    "def run_xgb(CONT, FREQ, PREDICT_HORIZON):\n",
    "    MODEL_RESULTS = dict()\n",
    "    for i in CONT:\n",
    "        MODEL_RESULTS[i] = {'MODEL':[],'RUN_TIME':[], 'Frequency':[], 'Prediction_Window':[], 'ACCURACY':[], \n",
    "                         'F1SCORE':[], 'PRECISION':[], 'RECALL':[]}\n",
    "    for c in CONT:\n",
    "        for f in FREQ:\n",
    "            for p in PREDICT_HORIZON:\n",
    "                X, dt, lb = ts_data(country = c, category = 'total', frequency = f, model = None) # build the dataset\n",
    "                train_s = int(len(X)*0.7)\n",
    "                test_s = len(X) - train_s\n",
    "                t = list()\n",
    "                t_ = list()\n",
    "                idx = list()\n",
    "\n",
    "                START_TIME = timeit.default_timer()\n",
    "\n",
    "                for i in range(0,int(test_s/p)): \n",
    "                    x_train, x_test, y_train, y_test = train_test_split_classification(X, train_s, p)\n",
    "                    \n",
    "                    # train the classifier \n",
    "                    clf=xgb.XGBClassifier(n_estimators=100, max_depth=8, learning_rate=0.1)\n",
    "                    clf=xgb.XGBClassifier()\n",
    "                    clf.fit(np.array(x_train),y_train.ravel())\n",
    "                    \n",
    "                    for j in range(0,p): # make classifications p-steps out of sample\n",
    "                        x_test_temp = np.array([x_test.iloc[j]])\n",
    "                        y_pred=clf.predict(x_test_temp)\n",
    "\n",
    "                        t_ = t_ + list(y_pred)\n",
    "                        t = t + [list(y_test)[j]]\n",
    "\n",
    "                    train_s += p\n",
    "\n",
    "                END_TIME = timeit.default_timer()\n",
    "                TIME = convert(END_TIME-START_TIME)\n",
    "                \n",
    "                # calculate model performance and return results in a dataframe \n",
    "                accuracy, f1score, precision, recall = model_performance(t_, t)\n",
    "                \n",
    "                MODEL_RESULTS[c]['MODEL'].append('XGB')\n",
    "                MODEL_RESULTS[c]['RUN_TIME'].append(TIME)\n",
    "                MODEL_RESULTS[c]['Frequency'].append(f)\n",
    "                MODEL_RESULTS[c]['Prediction_Window'].append(p)\n",
    "                MODEL_RESULTS[c]['ACCURACY'].append(accuracy)\n",
    "                MODEL_RESULTS[c]['F1SCORE'].append(f1score)\n",
    "                MODEL_RESULTS[c]['PRECISION'].append(precision)\n",
    "                MODEL_RESULTS[c]['RECALL'].append(recall)\n",
    "    return performance_table(MODEL_RESULTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function for naive baseline classifer\n",
    "def run_naive_baseline (CONT, FREQ, PREDICT_HORIZON):\n",
    "    MODEL_RESULTS = dict()\n",
    "    for i in CONT:\n",
    "        MODEL_RESULTS[i] = {'MODEL':[],'RUN_TIME':[], 'Frequency':[], 'Prediction_Window':[], 'ACCURACY':[], \n",
    "                         'F1SCORE':[], 'PRECISION':[], 'RECALL':[]}\n",
    "    for c in CONT:\n",
    "        for f in FREQ:\n",
    "            for p in PREDICT_HORIZON:\n",
    "                X = ts_data(country = c, category = 'total', frequency = f, model = 'naive_baseline') # build the dataset\n",
    "                train_s = int(len(X)*0.7)\n",
    "                test_s = len(X) - train_s\n",
    "                t = list()\n",
    "                t_ = list()\n",
    "                idx = list()\n",
    "                \n",
    "                START_TIME = timeit.default_timer()\n",
    "\n",
    "                for i in range(0,int(test_s/p)):\n",
    "                    train, test = train_test(X,train_s,p)\n",
    "                    \n",
    "                    for j in range(0,p): # make classifications p-steps out of sample\n",
    "                        y_hat = naive_baseline(train, test.index[j])\n",
    "                        t_ = t_ + list([y_hat])\n",
    "                        \n",
    "                        t = t + list([test.iloc[j]])\n",
    "                    \n",
    "                    train_s += p\n",
    "\n",
    "                END_TIME = timeit.default_timer()\n",
    "                TIME = convert(END_TIME-START_TIME)\n",
    "                \n",
    "                # calculate model performance and return results in a dataframe \n",
    "                accuracy, f1score, precision, recall = model_performance(t_, t)\n",
    "                \n",
    "                MODEL_RESULTS[c]['MODEL'].append('NAIVE BASELINE')\n",
    "                MODEL_RESULTS[c]['RUN_TIME'].append(TIME)\n",
    "                MODEL_RESULTS[c]['Frequency'].append(f)\n",
    "                MODEL_RESULTS[c]['Prediction_Window'].append(p)\n",
    "                MODEL_RESULTS[c]['ACCURACY'].append(accuracy)\n",
    "                MODEL_RESULTS[c]['F1SCORE'].append(f1score)\n",
    "                MODEL_RESULTS[c]['PRECISION'].append(precision)\n",
    "                MODEL_RESULTS[c]['RECALL'].append(recall)\n",
    "                \n",
    "    return performance_table(MODEL_RESULTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "def run_lstm (CONT, FREQ, PREDICT_HORIZON):\n",
    "    MODEL_RESULTS = dict()\n",
    "    for i in CONT:\n",
    "        MODEL_RESULTS[i] = {'MODEL':[],'RUN_TIME':[], 'Frequency':[], 'Prediction_Window':[], 'ACCURACY':[], \n",
    "                             'F1SCORE':[], 'PRECISION':[], 'RECALL':[]}\n",
    "    for c in CONT:\n",
    "        for f in FREQ:\n",
    "            if f in ['1H', '2H']: # we dont run LSTM on hourly or 2-hourly data due to long runtime\n",
    "                return\n",
    "            else:\n",
    "                for p in PREDICT_HORIZON:\n",
    "                    X = ts_data(country = c, category = 'total', frequency = f, model = 'naive_baseline') # build the dataset\n",
    "                    n_input, n_nodes, n_epochs, n_activation, n_optimize = [14, 80, 100, 'relu', 'Adam']\n",
    "\n",
    "                    lstm_x, lstm_y, lstm_dt = split_series(X.values, X.index, n_input)\n",
    "                    train_s = int(len(lstm_x)*0.7) # change from x to lstm_x\n",
    "                    test_s = len(lstm_x) - train_s # change from x to lstm_x\n",
    "                    t = list()\n",
    "                    t_ = list()\n",
    "                    idx = list()\n",
    "\n",
    "                    START_TIME = timeit.default_timer()\n",
    "\n",
    "                    for i in range(0,int(test_s/p)):\n",
    "                        train, test, datetime = train_test_lstm(lstm_x, lstm_y, lstm_dt, train_s, p)\n",
    "\n",
    "                        # train model using the train set \n",
    "                        train = train.reshape((train.shape[0], train.shape[1], 1))\n",
    "                        model = lstm(n_input, n_nodes, n_activation, n_optimize)\n",
    "                        model.fit(train, lstm_y[0:train_s], epochs = n_epochs, verbose=0)\n",
    "\n",
    "                        # make classifications p-steps out of sample\n",
    "                        for j in range(0,p):\n",
    "                            if (len(lstm_x)==train_s):\n",
    "                                break\n",
    "\n",
    "                            x_test_instance = lstm_x[train_s+j]\n",
    "                            x_test_instance = x_test_instance.reshape((1,n_input,1))\n",
    "\n",
    "                            t.append(test[j])\n",
    "                            t_.append(int(model.predict(x_test_instance,verbose=0)))\n",
    "\n",
    "                            idx.append(lstm_dt[train_s+j])\n",
    "\n",
    "                        train_s += p\n",
    "\n",
    "                    END_TIME = timeit.default_timer()\n",
    "                    TIME = convert(END_TIME-START_TIME)\n",
    "\n",
    "                    # calculate model performance and return results in a dataframe \n",
    "                    accuracy, f1score, precision, recall = model_performance(t_, t)\n",
    "\n",
    "                    MODEL_RESULTS[c]['MODEL'].append('LSTM')\n",
    "                    MODEL_RESULTS[c]['RUN_TIME'].append(TIME)\n",
    "                    MODEL_RESULTS[c]['Frequency'].append(f)\n",
    "                    MODEL_RESULTS[c]['Prediction_Window'].append(p)\n",
    "                    MODEL_RESULTS[c]['ACCURACY'].append(accuracy)\n",
    "                    MODEL_RESULTS[c]['F1SCORE'].append(f1score)\n",
    "                    MODEL_RESULTS[c]['PRECISION'].append(precision)\n",
    "                    MODEL_RESULTS[c]['RECALL'].append(recall)\n",
    "    \n",
    "    return performance_table(MODEL_RESULTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_knn(CONT, FREQ, PREDICT_HORIZON):\n",
    "    MODEL_RESULTS = dict()\n",
    "    for i in CONT:\n",
    "        MODEL_RESULTS[i] = {'MODEL':[],'RUN_TIME':[], 'Frequency':[], 'Prediction_Window':[], 'ACCURACY':[], \n",
    "                         'F1SCORE':[], 'PRECISION':[], 'RECALL':[]}\n",
    "    for c in CONT:\n",
    "        for f in FREQ:\n",
    "            for p in PREDICT_HORIZON:\n",
    "                X, dt, lb = ts_data(country = c, category = 'total', frequency = f, model = None)\n",
    "                train_s = int(len(X)*0.7)\n",
    "                test_s = len(X) - train_s\n",
    "                t = list()\n",
    "                t_ = list()\n",
    "                idx = list()\n",
    "\n",
    "                START_TIME = timeit.default_timer()\n",
    "                \n",
    "                for i in range(0,int(test_s/p)):\n",
    "                    x_train, x_test, y_train, y_test = train_test_split_classification(X, train_s, p)\n",
    "                    \n",
    "                    # train the classifier \n",
    "                    clf = KNeighborsClassifier(metric=DTW, n_neighbors = 1)\n",
    "                    clf.fit(np.array(x_train),y_train.ravel())\n",
    "                    \n",
    "                    for j in range(0,p): # make classifications p-steps out of sample\n",
    "                        x_test_temp = np.array([x_test.iloc[j]])\n",
    "                        y_pred=clf.predict(x_test_temp)\n",
    "\n",
    "                        t_ = t_ + list(y_pred)\n",
    "                        t = t + [list(y_test)[j]]\n",
    "                        \n",
    "                    train_s += p\n",
    "                    \n",
    "                \n",
    "\n",
    "                END_TIME = timeit.default_timer()\n",
    "                TIME = convert(END_TIME-START_TIME)\n",
    "                \n",
    "                # calculate model performance and return results in a dataframe \n",
    "                accuracy, f1score, precision, recall = model_performance(t_, t)\n",
    "                \n",
    "                MODEL_RESULTS[c]['MODEL'].append('KNN')\n",
    "                MODEL_RESULTS[c]['RUN_TIME'].append(TIME)\n",
    "                MODEL_RESULTS[c]['Frequency'].append(f)\n",
    "                MODEL_RESULTS[c]['Prediction_Window'].append(p)\n",
    "                MODEL_RESULTS[c]['ACCURACY'].append(accuracy)\n",
    "                MODEL_RESULTS[c]['F1SCORE'].append(f1score)\n",
    "                MODEL_RESULTS[c]['PRECISION'].append(precision)\n",
    "                MODEL_RESULTS[c]['RECALL'].append(recall)\n",
    "    return performance_table(MODEL_RESULTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "FREQ = ['1H', '2H', '24H']\n",
    "PREDICT_HORIZON = [1, 6, 12, 24]\n",
    "CONT = ['ENTIRE','NORTH_AMERICA']\n",
    "\n",
    "# run each model using the entire (global) and North America dataset subject to different \n",
    "TABLE_KNN = run_knn(CONT, FREQ, PREDICT_HORIZON)\n",
    "TABLE_RF = run_rf(CONT, FREQ, PREDICT_HORIZON)\n",
    "TABLE_XBG = run_xgb(CONT, FREQ, PREDICT_HORIZON)\n",
    "TABLE_NAIVE_BASELINE = run_naive_baseline(CONT, FREQ, PREDICT_HORIZON)\n",
    "TABLE_LSTM = run_lstm(CONT, FREQ, PREDICT_HORIZON)\n",
    "\n",
    "TABLES = [TABLE_RF, TABLE_XBG, TABLE_KNN, TABLE_NAIVE_BASELINE, TABLE_LSTM]\n",
    "CLASSIFICATION_PERFORMANCE = pd.concat(TABLES)\n",
    "\n",
    "CLASSIFICATION_PERFORMANCE.to_csv('Classification_Performance.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
